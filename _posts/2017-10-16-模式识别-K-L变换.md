---
layout: post
title: 模式识别之K-L变换
categories:
 - 模式识别与机器学习
tags:
 - 模式识别
 - K-L变换
 - PCA
---

卡洛南-洛伊(Karhunen-Loeve)变换(K-L变换): 
 
*  一种常用的特征提取方法
*  最小均方差意义下的最优正交变换
*  消除模式特征之间的相关性、突出差异性方面有最优的效果。
*  分为: 连续K-L变换、离散K-L变换

# K-L展开式


设一连续的随机实函数 $x(t)$ ,$T_1 \leq t \leq T_2$,则 $x(t)$可用已知的正交函数集 ${\phi_j(t),j=1,2,……}$ 的线性组合来展开，即:  
$x(t)=y_1\phi_1(t)+y_2\phi_2(t)+……+y_j\phi_j(t)+……$   
$x(t)=\sum_{j=1}^{\infty}y_j\phi_j(t) \quad, \qquad T_1 \leq t \leq T_2$  

函数集正交与向量正交概念类似，即任意两个函数做内积(积分)为0.  
在$T_1 \leq t \leq T_2$范围内，等间隔采样n个离散点，转化为离散形式。  
即$x(t)\rightarrow {x(1),x(2),……,x(n)}$  
$\phi_j(t)\rightarrow {\phi_j(1),\phi_j(2),……,\phi_j(n)}$  
写成向量形式:  
> $x = (x(1),x(2),…,x(n))^T$  
> $\phi_j = (\phi_j(1),\phi_j(2),…,\phi_j(n))^T$  
> $x = \sum_{j=1}^{n}y_j\phi_j=\Phi y$

其中:  
	$y = (y_1,y_2,…,y_n)^T$  
	$\Phi = (\phi_1,\phi_2,…,\phi_n)=\begin{bmatrix} \phi_1(1) & \phi_2(1) &\cdots &  \phi_n(1)\newline\phi_1(2) & \phi_2(2) &\cdots &  \phi_n(2)\newline \cdots & \cdots &\cdots & \cdots \newline 
\phi_1(n) & \phi_2(n) &\cdots &  \phi_n(n) \end{bmatrix}$  
每一列为正交函数集中的一个函数,小括号内的序号为采样点次序。

# 正交向量集的确定

$y=\Phi^Tx$  
目标是产生最优不相关的特征。
则 $\quad E[y(i)y(j)]=0 \quad i\neq j$
$R_y = E[yy^T]=E[(\Phi^Tx)(\Phi^Tx)^T]=E[\Phi^Txx^T\Phi]$
因为 $\Phi$ 是固定值,所以  
$R_y = \Phi^T E[xx^T]\Phi = \Phi^T R_x\Phi$  
$R_x$是自相关矩阵，是对每一个样本自相关矩阵的加权平均  
即$R_x \approx \frac{1}{n}\sum_{k=1}^{n}x_kx_k^T$


	

















